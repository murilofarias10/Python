{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa44d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "!pip install -q together\n",
    "!pip install -q gradio\n",
    "\n",
    "import gradio as gr\n",
    "from together import Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a447f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Ready!\n"
     ]
    }
   ],
   "source": [
    "# Get Client\n",
    "your_api_key = \"9806a2601560024637df1e4acd804862faa67e08637db6598d920b64eebba43e\"\n",
    "client = Together(api_key=your_api_key)\n",
    "\n",
    "def prompt_llm(prompt):\n",
    "    # This function allows us to prompt an LLM via the Together API\n",
    "\n",
    "    # model together.ai\n",
    "    model = \"meta-llama/Meta-Llama-3-8B-Instruct-Lite\"\n",
    "\n",
    "    # Calculate the number of tokens\n",
    "    tokens = len(prompt.split())\n",
    "\n",
    "    # Make the API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(\"LLM Ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86db957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Brazil is BrasÃ­lia.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of Brazil?\"\n",
    "\n",
    "print(prompt_llm(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb0922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respond function\n",
    "def respond(user_message, chat_history):\n",
    "    # Generate a response\n",
    "    response = \"Hello I am a naive bot\"\n",
    "\n",
    "    chat_history.append((user_message, response))\n",
    "    return \"\", chat_history, None\n",
    "\n",
    "# This is the interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
    "    gr.Markdown(\"## ðŸ¤– AI Chatbot\")\n",
    "    gr.Markdown(\"Enter your message below and let the chatbot respond!\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    user_input = gr.Textbox(\n",
    "        placeholder=\"Type your message here...\", label=\"Your Message\"\n",
    "    )\n",
    "    send_button = gr.Button(\"Send\")\n",
    "\n",
    "    send_button.click(\n",
    "        respond,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[user_input, chatbot],\n",
    "    )\n",
    "    user_input.submit(\n",
    "        respond,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[user_input, chatbot],\n",
    "    )\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54dadba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respond function\n",
    "def respond(user_message, chat_history):\n",
    "    prompt = f\"\"\"\n",
    "    You are a General, Funny AI Chatbot that loves to help people\n",
    "\n",
    "    Instructions:\n",
    "    - Make your answers at most 10 words\n",
    "    - Always start with saying 'Thank you for Responding'\n",
    "    - Only give the response to the message\n",
    "    - Please use the knoweldge base to answer the question if relevant\n",
    "\n",
    "    Knowledge base:\n",
    "    - I only speak spanish and portuguese a mix of the two\n",
    "\n",
    "    Respond to the user's message below:\n",
    "    {user_message}\n",
    "    \"\"\"\n",
    "    # Generate a response\n",
    "    response = prompt_llm(prompt)\n",
    "\n",
    "    chat_history.append((user_message, response))\n",
    "    return \"\", chat_history, None\n",
    "\n",
    "# This is the interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
    "    gr.Markdown(\"## ðŸ¤– AI Chatbot\")\n",
    "    gr.Markdown(\"Enter your message below and let the chatbot respond!\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    user_input = gr.Textbox(\n",
    "        placeholder=\"Type your message here...\", label=\"Your Message\"\n",
    "    )\n",
    "    send_button = gr.Button(\"Send\")\n",
    "\n",
    "    send_button.click(\n",
    "        respond,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[user_input, chatbot],\n",
    "    )\n",
    "    user_input.submit(\n",
    "        respond,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[user_input, chatbot],\n",
    "    )\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
